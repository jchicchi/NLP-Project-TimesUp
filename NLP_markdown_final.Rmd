---
title: 'NLP #TimesUp Project'
author: "Jennifer Chicchi"
date: "8/20/2019"
output:
  word_document: default
  html_document: default
  pdf_document: default
  fig_caption: no
---
```{r set-options, echo=FALSE, cache=FALSE}
options(width = 1000)
```

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE)
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
```

```{r, echo=FALSE}
setwd("C://Users/JenChicchi/Desktop/Canidium/Code files")
```


## Introduction to NLP
Our fundamental understanding of the human social world rests on interpreting words and concepts that are expressed in human language. One powerful and exciting tool that can help us to understand language is NLP (Natural Language Processing) technology. Though most methods that are central to NLP have been around for decades, the recent explosion in big data technology has empowered us to use such techniques in increasingly novel and useful ways. The purpose of this project was to demonstrate how NLP and data science methods can be used to extract meaningful insights about a recent social phenomenon, the #TimesUp movement. 

### #TimesUp Movement
In recent years there has been spreading awareness of sexual harassment and increased activism surrounding this issue. The #MeToo movement, which began on Twitter in 2017, focused on confronting sexual assault and harassment, as well as making specific calls to action, such as asking for apology or other compensatory responses from perpetrators. The #MeToo movement has been seen as a response to issues of general sexual harassment, but there have also been more targeted efforts, like #TimesUp, which has specifically focused on sexual harassment in the workplace. The #TimesUp movement began in 2018 and has been mostly understudied compared to the #MeToo movement. What I wanted to know from this analysis was whether and how NLP techniques could be used to aid in our collective understanding of this recent social movement. While I didn’t enter this analysis with a specific hypothesis in mind, I wanted to see what we could learn from using exploratory techniques, spanning simple data visualizations all the way through advanced machine learning clustering algorithms. My hope in doing so was to learn more about the movement and possibly uncover some insights that could lead to more specific hypothesis for future analyses. 

### Analysis Outline
 1.	Data acquisition via Twitter API
 2.	Data cleaning using regular expressions
 3.	Feature engineering including text metadata, lubridate package, and sentiment
 4.	Exploratory analysis using dplyr and ggplot2
 5.	Machine learning NLP preprocessing techniques
 6.	Unsupervised machine learning methods for cluster analysis

&nbsp;
&nbsp;

#### 1. Data acquisition via Twitter API
Having chosen the topic that I wanted to explore in this data science project, the next step was to decide how to gather the data. There are many social networks and apps that have their own interface that programmers can work with. These interfaces are called APIs (Application Programming Interface). Here, I chose to focus on the Twitter API. Here are the steps I followed to set up the Twitter API: 

&nbsp;

 1. I visited the Twitter Developer’s Site at:  <http://dev.twitter.com>
 2. I signed in with my Twitter account
 3. I visited Twitter's app website at: <http://apps.twitter.com>
 4. I created a new application
 5. I filled out the application details with: Name, Description, Website, Callback URL. The results appeared as follows: 
 
![](twitter_pic1.png)
![](twitter_pic2.png)

 6. I created my access token
 7. I chose the access type I needed
 8. I made a note of my OAuth Settings, as seen below: 
 9. I then pasted the Consumer Key, Consumer Secret, OAuth Access Token and OAuth Access Token Secret into R. Again, see below: 
 
 ![](twitter_pic3.png)

&nbsp;

Next, I was ready to code. First I set the API credentials and connected to Twitter Oauth. 
&nbsp;

```{r, message=FALSE}
library(twitteR)

consumer_key        <- "dYCPvsWmjtoqDxyQ73Jx0Wd0J" 
consumer_secret     <- "s3EhmK67BVEWMurtEe5k4RjaeisnkQfy109VpJZD225ws3Q4Zw" 
access_token        <- "570660011-z5ci1luVcgWAIN9vKxxDi57Zg3UQIGqwu44z5dGv" 
access_token_secret <- "xH9any0kf8VlnkLeCfurrteOwZpNaoC7GuFCeh7ORa0oH" 
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_token_secret)
```

&nbsp;

Then I extracted up to 20,000 Tweets containing the search term #TimesUp. 
```{r, eval=FALSE}
times_up_tweets <- searchTwitter("#TimesUp", n=20000, lang ="en")
```

```{r, echo=FALSE}
tweets_df <- read.csv('nlptweets.csv')
```
&nbsp;

Next I converted the .json output to an R data frame
```{r, eval=FALSE}
tweets_df <- twListToDF(times_up_tweets)
```

&nbsp;

I ran simple descriptive analytics on the data frame. 

```{r}
summary(tweets_df[,c(3:6)])
```

&nbsp;

And we can see a sample of our Tweets
```{r}
print(substr(tweets_df[1, 2], 0, 80))
```

&nbsp;

At this point our Tweets were not clean. In the next section we'll address this. 

&nbsp;

#### 2. Data cleaning using regular expressions

Please note, prior to doing this analysis, I studied how to write for loops, if/else logic, and regular expression patterns. All of these techniques are necessary for performing advanced text analytics. The details of this work can be found here. <https://github.com/jchicchi/NLP-Project-TimesUp/>

&nbsp;

###### *Context*
Regular expressions are character-matching algorithms that allow us to identify specific key phrases or other patterns in our text data. They can be used to perform targeted searches, like if you want to find all instances of the word ‘TimesUp’, all hashtags, all urls, etc. They also can be used for removing certain patterns from the text, such as URL’s or special characters, as is common in data cleaning. 

&nbsp;

###### *Methodology*
I used a series of regular expressions for data cleaning, as detailed below. I also performed common data cleaning techniques, such as removing trailing and leading whitespace from the text and lowercasing all the words. 

&nbsp;

###### *Code*

Here, we can use regex patterns to find certain types of text, such as URL's.
```{r, message=FALSE}
library(stringr)

# Extract all URL's
urlp<-"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+"
str_extract_all(tweets_df$text[1:100], urlp)[0:5]
```

&nbsp;

Next we'll remove various sources of noise in our text. 

```{r}
# Remove all URL's
tweets_df$cleaned_text <- str_remove_all(tweets_df$text, urlp)

# Remove RTs
retweet_pattern <- "(RT|via)((?:\\b\\W*@\\w+)+)"
tweets_df$cleaned_text <- str_remove_all(tweets_df$cleaned_text, retweet_pattern)

# Remove @ shoutouts
shoutout_pattern <- "@\\w+"
tweets_df$cleaned_text <- str_remove_all(tweets_df$cleaned_text, shoutout_pattern)

# Remove \n
newline_pattern <- '\n'
tweets_df$cleaned_text <- str_remove_all(tweets_df$cleaned_text, newline_pattern)

# Remove &amp
amp_pattern <- '&amp;'
tweets_df$cleaned_text <- str_remove_all(tweets_df$cleaned_text, amp_pattern)

# Remove hashtags
hashtag_pattern <- "#\\S+"
tweets_df$cleaned_text <- str_remove_all(tweets_df$cleaned_text, hashtag_pattern)

# Remove emojis
tweets_df$cleaned_text <- str_remove_all(tweets_df$cleaned_text, "[^[:ascii:]]")

# Remove all remaining punctuation
tweets_df$cleaned_text <- str_remove_all(tweets_df$cleaned_text, "[[:punct:]]")
```

&nbsp;

Finally, we will perform some extra cleaning steps, such as lowercasing words and adding a final regex pattern to remove special characters the previous patterns missed. We will also trim any excess white space on either the front or end of the strings. 

&nbsp;

```{r}
# Lowercase all words
tweets_df$cleaned_text <- str_to_lower(tweets_df$cleaned_text)

# Extra regex step 
tweets_df$cleaned_text <- str_remove_all(tweets_df$cleaned_text, 'http')

# Trim trailing and leading white spaces
tweets_df$cleaned_text <- str_squish(tweets_df$cleaned_text)
```


&nbsp;

Now our text data is much cleaner and we are ready to explore further. 

```{r}
print(substr(tweets_df$cleaned_text[1], 0, 80))
```

&nbsp;
&nbsp;

#### 3. Feature engineering including text metadata, lubridate package, and sentiment

&nbsp;

###### *Context*
In machine learning and analysis in general, oftentimes you can extract more signal by creating new features based on the information you already have. This step is called feature engineering. Features are the variables found in the given problem set that can strongly/sufficiently help us build an accurate predictive model. Due to its inherent richness as a data source, text offers us much opportunity for creating features. 


&nbsp;

###### *Methodology*
I used the lubridate package to create columns based on the date and time of the tweets. I also summarized each tweet in terms of its word count, its number of characters, and a metric I created called word sophistication. Finally, I performed sentiment analysis on the tweets to examine how emotionally positive or negative the text was. 

&nbsp;

I start with some basic date conversions. 
```{r, message=FALSE}
library(lubridate)
# Convert date to yyyy/mm/dd hh:mm:ss format 
tweets_df$created <- ymd_hms(tweets_df$created)

# Converts from Coordinated Universal Time UTC/Greenwich Mean Time to Mountain Time Zone MDT (the one I'm in)
tweets_df$created <- with_tz(tweets_df$created)
```

&nbsp;

Next I engineer some features
```{r}
tweets_df$hour <- hour(tweets_df$created)
tweets_df$month <- month(tweets_df$created)
tweets_df$weekday <- wday(tweets_df$created)  #which weekday a Tweet was on
```

&nbsp;

Next I extract the sentiment (emotion) of the Tweet
```{r, message=FALSE}
library(syuzhet)
word.df <- as.vector(tweets_df$cleaned_text)

# Calls the NRC sentiment dictionary to calculate the presence of eight different emotions and their corresponding valence in a text file.
emotion.df <- get_nrc_sentiment(word.df)

str(emotion.df)  
```

&nbsp;

We can use the NRC sentiment scores to explore our Tweets by their emotion. 

&nbsp;

Find angry tweets
```{r}
angry_index <- emotion.df$anger > 0
print(substr(tweets_df$cleaned_text[angry_index][1], 0, 80))
```

&nbsp;

Find positive tweets
```{r}
pos_index <- emotion.df$positive > 0
print(substr(tweets_df$cleaned_text[pos_index][1], 0, 80))
```

&nbsp;

Find negative tweets
```{r}
neg_index <- emotion.df$negative > 0
print(substr(tweets_df$cleaned_text[neg_index][1], 0, 80))
```

&nbsp;

Let's add all the NRC Sentiment classifications to our data frame 
```{r}
tweets_df <- cbind(tweets_df, emotion.df)
head(tweets_df[,22:26])
```

&nbsp;

Finally we'll add a column for numeric sentiment
```{r}
sent.value <- get_sentiment(word.df)
tweets_df$sent <- sent.value
```

&nbsp;

We'll add a feature that captures the number of characters in the tweets
```{r}
# Number of characters
tweets_df$nchar_raw <- nchar(as.character(tweets_df$text))
tweets_df$nchar_clean <- nchar(as.character(tweets_df$cleaned_text))

```

&nbsp;

To obtain the word counts in the tweets, first we must tokenize our text. This means splitting each tweet into a list of words. 

```{r, message=FALSE}
library(tokenizers)
tokens <- tokenize_words(tweets_df$cleaned_text)
```

&nbsp;

Create feature for word counts
```{r}
word_counts <- numeric()
for (i in 1:nrow(tweets_df)){
        word_counts[i] <- length(tokens[[i]])
}
tweets_df$word_count <- word_counts
print(tweets_df$word_count[1:5])
```

&nbsp;

Create feature for unique word counts
```{r}
unique_word_counts <- numeric()
for (i in 1:nrow(tweets_df)){
        unique_word_counts[i] <- length(unique(tokens[[i]]))
}
tweets_df$unique_word_counts <- unique_word_counts
print(tweets_df$unique_word_counts[1:5])
```

&nbsp;

We can now leverage these two features to create a new feature called word sophistication (#distinct words/#total words)
```{r}
tweets_df$sophistication <- tweets_df$unique_word_counts/tweets_df$word_count
print(tweets_df$sophistication[1:5])
```

&nbsp;

Now that we have created features, we are now ready to begin exploring our data. 
&nbsp;

#### 4. Exploratory analysis using dplyr and ggplot2

&nbsp;

###### *Context*
&nbsp;

After having created features and cleaning the data, I was now ready for exploratory analysis. Here, although I didn’t have any specific hypotheses in mind yet about the nature of the #TimesUp movement, I saw this as an opportunity to uncover some interesting findings that might tell a story or converge on a common theme. 

&nbsp;

###### *Methodology*
&nbsp;

I used the dplyr package to partition our data in various ways and summarize the partitions. I also used ggplot2 to visualize some patterns in the data. 

&nbsp;

Let's view the proportion of retweets across hours in the day

&nbsp;

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
```


```{r, message=FALSE}
tweets_df %>% 
        group_by(hour) %>% 
        summarize(prop_retweets = mean(isRetweet))
```
&nbsp;

From midnight to 6am there may be a hint of a decreasing trend in the proportion of retweets.


&nbsp;

Let's also check the sentiment by hours in the day

&nbsp;

```{r}
tweets_df %>%
        group_by(hour) %>%
        summarize(mean_sent = mean(sent),
                  median_sent = median(sent)) %>%
        as.data.frame()
```

&nbsp;

The most positive tweets come between midnight and 2am. The most negative tweets come between 6 and 9pm.


&nbsp;

Finally let's see if there are any differences in tweet properties depending on whether it was retweeted.

&nbsp;

```{r}
tweets_df %>%
        group_by(isRetweet) %>%
        summarize(n_tweets=n(),
                  avg_nchar_tweet = mean(nchar_raw),
                  avg_nchar_clean_tweet = mean(nchar_clean),
                  avg_sent = mean(sent))
```

&nbsp;

Here we can see some interesting differences. Retweets tend to have more characters and higher (more positive) sentiment. 

&nbsp;

Let's see if overall tweet emotions, specifically anger, vary across the week. 

&nbsp;

```{r}
tweets_df %>%
        group_by(weekday) %>%
        summarize(m=mean(anger), n=n())
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
```

&nbsp;

```{r}
ggplot(data=tweets_df, aes(weekday))+
  geom_bar(aes(fill=as.factor(anger)), position="fill")
```

&nbsp;

This table suggests that weekend tweets tend to be angrier. One could ask whether any other properties of tweets vary by weekday. Let's try checking the proportion of retweets across the week. 

&nbsp;

```{r}
tweets_df %>%
        group_by(weekday) %>%
        summarize(m=mean(isRetweet), n=n())
```

&nbsp;

This table suggests that there are relatively fewer retweets on weekends. Connecting the two above patterns, perhaps then, angry tweets are less likely to be retweeted. Let's explore that possibility. 

&nbsp;

```{r}
ggplot(data=tweets_df, aes(weekday))+
  geom_bar(aes(fill=as.factor(isRetweet)), position="fill")
```

&nbsp;

```{r}
tweets_df %>%
        group_by(anger) %>%
        summarize(m=mean(isRetweet), n=n())
```

&nbsp;

```{r}
ggplot(data=tweets_df, aes(anger))+
  geom_bar(aes(fill=as.factor(isRetweet)), position="fill")
```

&nbsp;

Here, we see that relative to unangry tweets (having an anger score of 0), tweets become more likely to be shared when there is a slight anger in them (with a score of 1 or 2), but much less likely to be shared when there is extreme anger (having a score of 3 or 4 or 5). 

Perhaps an effective strategy for getting one's voice circulated on Twitter is to express slight, but not extreme anger. 

&nbsp;

Next let's see the densities of retweets by whether they occurred on a weekend.

&nbsp;


```{r}
tweets_df$isWeekend <- as.factor(tweets_df$weekday %in% c(6, 7, 8))
```

```{r, echo=FALSE}
p8 <- ggplot(tweets_df, aes(x = retweetCount, fill = as.factor(isWeekend))) + 
        geom_density(position = "stack", alpha = 0.6) + 
        scale_x_continuous(name = "Retweet Count",
                            breaks = seq(0, 1000, 100),
                            limits=c(0, 1000)) +
        scale_y_continuous(name = "Density") +
        ggtitle("Density plot of Retweets") +
        theme_bw() +
        scale_fill_brewer(palette="Accent")
```

```{r, echo=FALSE}
p8
```

&nbsp;

Here we can see the densities of retweet counts. Notice an overall similar pattern on weekends vs weekdays. 

&nbsp;

Next, let's check to see if there are any interesting linear relationships in the data. 
&nbsp;

```{r, message=FALSE, echo=FALSE}
#ReTweets more often long if they have a negative sentiment. 
ggplot(tweets_df, aes(x=nchar_clean, y=sent, colour= isRetweet)) + geom_point() + xlim(0,250) + geom_smooth(method = "lm") + labs(title = "Longer Retweets have Negative Sentiment") + xlab("Number of characters") + ylab("Sentiment Score")
```

&nbsp;

It looks like there is a linear relationship between sentiment and the number of tweet characters. However, this may depend on whether it was a retweet, with retweets showing the negative linear trend, and non-retweets showing no linear trend. Let's see the summary report of the linear regression model on just retweets. 

&nbsp;

```{r}
mod <- lm(data = subset(tweets_df, isRetweet=="TRUE"), sent~nchar_clean)
summary(mod)
```

&nbsp;

Indeed, the linear relationship is highly significant with a p-value of < .0001. However, one core assumption of regression is that rows are independent. Here, we have many duplicate rows due to the fact that these are retweets. So let's analyze the relationship again after subsetting just to unique tweets. 

&nbsp;

```{r}
deduped.data <- unique(subset(tweets_df, isRetweet=="TRUE")[ , c('nchar_clean','sent')] )
mod2 <- lm(data=deduped.data, sent~nchar_clean)
summary(mod2)
```

&nbsp;

```{r, echo=FALSE}
ggplot(deduped.data, aes(x=nchar_clean, y=sent)) + geom_point() + xlim(0,250) + geom_smooth(method = "lm") + labs(title = "There is no relationship between sentiment and tweet length here") + xlab("Number of characters") + ylab("Sentiment Score")

```

&nbsp;

This suggests the previous linear trend could have been driven by a tweet or tweets that was frequently retweeted and also had few characters and positive sentiment. 

#### Conclusions

Taken together, we have learned quite a bit about how people are engaging with the #TimesUp movement on Twitter. 

&nbsp;


* From midnight to 6am there is a decreasing trend in the proportion of retweets. This makes sense, considering these are "off hours"" when many people are not online. 
* The most positive tweets come between midnight and 2am. The most negative tweets come between 6 and 9pm. Although there could be multiple explanations, one possible reason for this effect is that people are stressed out after work hours. 
* Retweets tend to have more characters and higher (more positive) sentiment. This could suggest a strategy for people wanting their tweet to go viral. Namely, it could pay off to develop a more thought-out tweet and to keep the sentiment more positive than negative. 
* I also found that weekend tweets tend to be angrier and also retweeted less often. More nuanced breakdown of the retweet by anger relationship suggests there is an optimal level of anger, such that tweets that are slightly, but not extremely angry, are more likely to be shared than unangry tweets. Considering this, to maximize the chance of a retweet, it may be well-advised to express slight, but not extreme anger. 


#### 5. Cluster analysis to detect common themes in the text

Cluster analysis is a form of unsupervised machine learning in which the algorithms will find common latent structures in the data. Here, in this case, we will apply clustering algorithms to find common text structures, like semantic themes. We'll try different clustering algorithms, such as K-Means, Hierarchical clustering, and Latent Dirichlet Allocation. 

```{r, message=FALSE, echo=FALSE}
library(tm)
library(SnowballC)
library(ggplot2)
library(wordcloud)
```


```{r}
input_text <- tweets_df$cleaned_text
```
##### Context

To do various machine learning operations, we will need to preprocess the text data further than we already have. The first step in R is to create a Corpus object from the tm package. 

```{r, message=FALSE, warning=FALSE}
# make a corpus object
Corpus <- Corpus(VectorSource(input_text)) 
```

&nbsp;


One common preprocessing step is to remove words that occur too frequently to be meaningful, such as 'a' and 'the'. These are called 'stopwords'

```{r, message=FALSE, warning=FALSE}
Corpus = tm_map(Corpus, removeWords, stopwords("english"))
```

&nbsp;

We can also define our own unique stopword list and remove all words from that list. 
```{r, message=FALSE, warning=FALSE}
customStopwords <- c("can", "say","one","way","use",
                     "also","howev","tell","will",
                     "much","need","take","tend","even",
                     "like","particular","rather","said",
                     "get","well","make","ask","come","end",
                     "first","two","help","often","may",
                     "might","see","someth","thing","point",
                     "post","look","right","now","think","’ve ","’re ")

#remove custom stopwords
Corpus <- tm_map(Corpus, removeWords, customStopwords)
```

&nbsp;

Next, we can also stem the documents. This will reduce various versions of a word, such as 'loving', 'loves', 'loved' to just the stem 'lov'. This will help us condense our signal as we prepare to build a model. 

```{r, message=FALSE, warning=FALSE}
Corpus = tm_map(Corpus, stemDocument)
```

#####DTM
Now that we have preprocessed the data, we can take the next step to leverage more sophisticated techniques by representing the text itself numerically. To this end, a standard NLP method is to convert the documents (in this case, tweets) into a sparse vector of numbers. The most common version of this method is called ‘Bag of Words’, in which each row represents a tweet and each column represents a word in the Corpus vocabulary. It can be demonstrated as follows:

![](bow_pic.png)

&nbsp;

```{r}
# Create sparse document/term matrix
DTM <- DocumentTermMatrix(Corpus)
inspect(DTM)
```

&nbsp;

We can now call functions on our DTM like to find the most frequent words.
```{r}
findFreqTerms(DTM, 1000)
```

#####KMeans
Next, to prepare our data for the K-means clustering algorithm, we must convert our DTM to a standard matrix format. 
```{r}
m <- as.matrix(DTM)
```

&nbsp;

Then we must create a matrix that stores the pairwise distances among all our document-term vectors. 
```{r, eval=FALSE}
d <- dist(m)
```

```{r, echo=FALSE}
d <- read.csv('distance_matrix.csv')
d$X <- NULL
d <- as.dist(d)
```

&nbsp;

First we'll test our clustering algorithm with just two clusters. 

```{r}
kfit <- kmeans(d, centers=2, nstart=1)
```

&nbsp;

Here we can see properties of our iteration, such as the total within sums of squares and between sums of squares. 
```{r, echo=FALSE}
print(paste('The within SS values for our 2 clusters are', kfit$withinss[1], 'and', kfit$withinss[2]))
print(paste('The between SS for our clusters is', kfit$betweenss))
```

&nbsp;

But we can specify any number of n possible clusters for n points in our data. How can we tell which is the optimal amount? One thing we can do is to try many iterations varying K each iteration and keep track of which K gives us the best tradeoff of low K values and low within SS. 

&nbsp;

We will now test our K-means algorithm across 28 different levels of K. We will store our results in a results bin on each iteration. 

```{r, echo=FALSE}
k_results_bin <- read.csv('k_results_bin.csv')
```

```{r, eval=FALSE}
k_results_bin <- data.frame(k=2:29,
                            withinss=numeric(28))

for (i in 2:29) {
        print(paste('On iteration:', i))
        kfit <- kmeans(d,centers=i,nstart=1)
        k_results_bin[i-1, 'withinss'] <- sum(kfit$withinss)
}
```

&nbsp;

Next we can visualize our results using an Elbow plot
```{r}
plot(2:29, k_results_bin[1:28, 'withinss'], 
     type="b", xlab="Number of Clusters",ylab="Within groups sum of squares")
```

&nbsp;

Looks like K = 9 is reasonable. 
```{r}
best_kfit <- kmeans(d,centers=9,nstart=1)
```

&nbsp;

Let's see how many documents belong to each cluster. 
```{r}
table(best_kfit$cluster)
```

&nbsp;

Next let's assign each tweet to its corresponding cluster. This way we can more easily describe the themes in our clusters. 
```{r}
tweets_df$clusters <- as.numeric(best_kfit$cluster)
```

&nbsp;

We can now filter the data to just tweets belonging to each cluster. 
```{r}
clust1 <- tweets_df[tweets_df$clusters == 1, ]
clust2 <- tweets_df[tweets_df$clusters == 2, ]
clust3 <- tweets_df[tweets_df$clusters == 3, ]
clust4 <- tweets_df[tweets_df$clusters == 4, ]
clust5 <- tweets_df[tweets_df$clusters == 5, ]
clust6 <- tweets_df[tweets_df$clusters == 6, ]
clust7 <- tweets_df[tweets_df$clusters == 7, ]
clust8 <- tweets_df[tweets_df$clusters == 8, ]
clust9 <- tweets_df[tweets_df$clusters == 9, ]
```

&nbsp;

Next, to describe our clusters, let's build a function that will return the top n words within a text column. We can then apply this function across our cluster segments. 

```{r}
# Write a function for the above syntax
summarize_text <- function(a_col, nwords=20){
        xCorpus <- Corpus(VectorSource(a_col)) # make a corpus object
        xCorpus = tm_map(xCorpus, removeWords, stopwords("english"))
        xCorpus = tm_map(xCorpus, stemDocument)
        xDTM <- DocumentTermMatrix(xCorpus)
        text_summary <- sort(slam::col_sums(xDTM), decreasing=TRUE)[1:nwords]
        
        return(text_summary)
}
```

&nbsp;

Here we can see the top 20 words in cluster 1
```{r, message=FALSE, warning=FALSE}
clust1_summary <- summarize_text(a_col=clust1$cleaned_text, nwords=20)
clust1_df <- data.frame(words=names(clust1_summary),
                        freq=clust1_summary)

ggplot(clust1_df, aes(x = reorder(words, -freq), y = freq)) + 
        geom_bar(stat = "identity") + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
        labs(x='Words', y='Freq', title='Cluster1 Summary') + 
        theme(plot.title = element_text(hjust = 0.5))
```

&nbsp;

The frequency distribution of this cluster's words is uniform, suggesting that it perhaps reflects one retweet. 

&nbsp;

We can wrap the above code into a function and apply it to the remaining clusters. 

```{r}
plot_cluster_summary <- function(a_col, clust_num){
        clust_sum <- summarize_text(a_col=a_col, nwords=20)
        clust_df <- data.frame(words=names(clust_sum),
                                freq=clust_sum)
        
        p1 <- ggplot(clust_df, aes(x = reorder(words, -freq), y = freq)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + labs(x='Words', y='Freq', title=paste('Cluster', clust_num,'Summary'))+theme(plot.title = element_text(hjust = 0.5))
        
        p1
}
```

```{r, message=FALSE, warning=FALSE, echo=FALSE}
plot_cluster_summary(a_col=clust2$cleaned_text, clust_num=2)
```

&nbsp;

This cluster is picking up tweets related to Adrienne Bennett, the first black female master plumber in Michigan. This was also a retweet. 

&nbsp;

```{r, message=FALSE, warning=FALSE, echo=FALSE}
plot_cluster_summary(a_col=clust3$cleaned_text, clust_num=3)
```

&nbsp;

This cluster seems to reflect a racial component. Perhaps these tweets are comparing TimesUp to movements of racial justice. 

&nbsp;

```{r, message=FALSE, warning=FALSE, echo=FALSE}
plot_cluster_summary(a_col=clust4$cleaned_text, clust_num=4)
```

&nbsp;

This cluster theme is less clear. Perhaps it is reflecting calls to action, such as 'fought', 'shout', and 'assemble'

&nbsp;

```{r, message=FALSE, warning=FALSE, echo=FALSE}
plot_cluster_summary(a_col=clust5$cleaned_text, clust_num=5)
```

&nbsp;

This cluster seems to directly tap themes about TimesUp, such as women, sexual harassment, work, assault, etc. The word 'study' shows up, suggesting that maybe some of the tweets in this cluster are citing a research publication. 

&nbsp;

```{r, message=FALSE, warning=FALSE, echo=FALSE}
plot_cluster_summary(a_col=clust6$cleaned_text, clust_num=6)
```

&nbsp;

This cluster theme is also not immediately clear. But the uniformity of most of the words suggests it is picking up one retweet. 

&nbsp;

```{r, message=FALSE, warning=FALSE, echo=FALSE}
plot_cluster_summary(a_col=clust7$cleaned_text, clust_num=7)
```

&nbsp;

This cluster taps themes about equal pay and jobs. 

&nbsp;

```{r, message=FALSE, warning=FALSE, echo=FALSE}
plot_cluster_summary(a_col=clust8$cleaned_text, clust_num=8)
```

&nbsp;

This cluster seems to be about strong women and empowerment. 

```{r, message=FALSE, warning=FALSE, echo=FALSE}
plot_cluster_summary(a_col=clust9$cleaned_text, clust_num=9)
```

&nbsp;

This also seems to reflect general themes about the TimesUp movement, like women, sexual, harass, work, rape, abuse, assult, etc. It also has Trump in it, presumably because of some past comments he has made about women. 

##### Summary
In sum, we can use cluster analysis like K-means to find common themes in our tweet data. 


##### Topic Modeling (LDA)
```{r}
library(topicmodels)
```


Topic modeling is another powerful clustering algorithm that decomposes our DTM into count matrices that we can use to estimate word distributions for each topic. 

The broad goals of Topic Modeling (LDA):
1. Estimate a distribution of topics over our documents (K)
2. Estimate a distribution of words over topics

In LDA, we consider documents mixtures of topics. This is distinct from K-means (in which we consider a document as belonging to only 1 cluster)

We will use a process called Gibb's sampling to estimate our distributions. 

&nbsp;

```{r}
#Set parameters for Gibbs sampling
burnin <- 4000
iter <- 2000
thin <- 500
seed<-list(2003,5,63,100001,765) # note, second param must be equal to nstart
nstart <- 5 
best <- TRUE
```

&nbsp;

We'll set our number of topics to be 10. This can be configured, but to compare to our K-means, let's consider 10 topics. 
```{r}
#Number of topics
k <- 10
```

&nbsp;

Because of stopword and stem removal, some documents have 0 words. Let's remove these before we run topic modeling

```{r}
raw.sum=apply(DTM,1,FUN=sum) #sum by raw each raw of the table
DTM=DTM[raw.sum!=0,]
```

&nbsp;

Here we will run the algorithm. 
```{r, eval=FALSE}
set.seed(42)
ldaOut <-LDA(DTM,k, method="Gibbs", 
             control=list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
```

&nbsp;

We can see the count of documents by topic 
```{r, echo=FALSE}
ldaOut.topics <- read.csv('ldatopics.csv')
ldaOut.topics <- ldaOut.topics$V1
```

```{r, eval=FALSE}
ldaOut.topics <- as.matrix(topics(ldaOut))
```

```{r}
print(table(ldaOut.topics))
```

&nbsp;

Importantly, we can also view the word distribution per topic. 
```{r, eval=FALSE}
ldaOut.terms <- as.matrix(terms(ldaOut,20))
```

&nbsp;

```{r, echo=FALSE}
ldaOut.terms <- read.csv('ldaterms.csv')
ldaOut.terms$X <- NULL
```

&nbsp;

Topic 1
```{r}
ldaOut.terms[,1]
```

&nbsp;

This topic seems to reflect social justice in general. 

&nbsp;

```{r}
ldaOut.terms[,1:5]
```

&nbsp;

* Topic 2 could reflect something about passing a bill. It seems moderately political.
* Topic 3 appears to be more about issues of physical safety, like rape and assault.
* Topic 4 looks like it reflects more about issues at work. 
* Topic 5 could be a mixture of themes, here some about Planned Parenthood, some about abuse, and some about equal pay in the workforce. 

&nbsp;

```{r}
ldaOut.terms[,6:10]
```

&nbsp;

* Topic 6 overlaps with one of our clusters from K-means, focusing on Adrienne Bennett. 
* Topic 7 is interesting. It may include themes about gender and church, together or individually. Either way, this is a distinct cluster compared to what we found in K-means. 
* Topic 8 may suggest themes about sexual harassment and also the 'cartoon' and '1call' tweet that showed up in K-means. 
* Topic 9 is not entirely clear. Topic 10 suggests themes about women empowerment and social change. 

##### Conclusions
Both K-Means and topic modeling (LDA) gave us insight into common themes that are showing up in the text data. Issues of harassment, abuse, empowerment, and social justice are all present in both analyses. 

### Final Conclusions

Our analysis has demonstrated many advanced text analytics methods and machine learning techniques that we can leverage to better understand the #TimesUp movement. In our exploratory data analysis, we found patterns that suggested possible actions we could take to increase one's impact in the #TimesUp movement online. The cluster analysis showed us some common themes that people are tweeting about. Taken together, one could tweet about such themes, while also leveraging the possible strategies we found in the earlier analysis. 
